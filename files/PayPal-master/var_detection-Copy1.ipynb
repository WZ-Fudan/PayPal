{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "task: Tag value type of variable automatically\n",
    "author: Zheng Wei\n",
    "latest modification date: 2018/05/16\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"----------------------PART ONE: Get Return Type-----------------------\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# load data and grep variables' names.\n",
    "sample_data = pd.read_csv('C:/Users/zhewei/Desktop/material file/BREAllInOneTrack_10000.csv', sep = '\\x07', low_memory=False, encoding='utf-8')\n",
    "variable_data = pd.read_excel(r'C:/Users/zhewei/Desktop/material file/variables.xlsx')\n",
    "# sample_variable_name = list(sample_data.iloc[0])\n",
    "variable_name = list(variable_data['Variable Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "    \n",
    "def calc_stat(data):\n",
    "    \"\"\"\n",
    "    Given a column sample data of a variable, calculate its skew and kurt. \n",
    "    If the data type is abnormal or sigma of data is zero, we assign 1E7 its skew and kurt.\n",
    "    \n",
    "    @para: a column sample data \n",
    "    @return: a list, example: [skew, kurt]\n",
    "    \"\"\"\n",
    "    skew = 1E7\n",
    "    kurt = 1E7\n",
    "    length = len(data)\n",
    "    try:\n",
    "        try:\n",
    "            miu, miu2 = sum(data)/length, sum(np.array(data)**2)/length\n",
    "            sigma = math.sqrt(miu2 - miu*miu)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                miu3 = sum(np.array(data)**3)/length\n",
    "                if sigma != 0:\n",
    "                    skew = (miu3 -3*miu*sigma**2-miu**3)/(sigma**3)\n",
    "            except:\n",
    "                pass\n",
    "            finally:\n",
    "                try:\n",
    "                    miu4 = sum((np.array(data) - miu)**4)/length\n",
    "                    if sigma != 0:\n",
    "                        kurt = miu4/(sigma**4)\n",
    "                except:\n",
    "                    pass\n",
    "        return [skew, kurt]\n",
    "    except TypeError:\n",
    "        return [skew, kurt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge(data_name, data):\n",
    "    \"\"\"\n",
    "    Given the sample data of variable, return the list including: \n",
    "    return type, missing rate, distinct number and a small sample.\n",
    "    \n",
    "    @param data_name: name of a variable\n",
    "    @param data: sample data of a variable\n",
    "    \n",
    "    @return list:[return type, missing rate, distinct numbe, top5 of data]\n",
    "    \"\"\"\n",
    "    \n",
    "    # part each instance by data form\n",
    "    string_obj, int_obj, double_obj = [], [], []\n",
    "    number_nan = 0\n",
    "    for item in data:\n",
    "        if item != item:\n",
    "            number_nan += 1\n",
    "            continue\n",
    "        else:\n",
    "            item = str(item)\n",
    "        try:\n",
    "            int_obj.append(int(item))\n",
    "        except ValueError:\n",
    "            try:\n",
    "                double_obj.append(float(item))\n",
    "            except ValueError:\n",
    "                string_obj.append(item)\n",
    "    # check empty data\n",
    "    if number_nan == len(data):\n",
    "        return 'NO DATA', 1, 0, 1E7, 1E7, []\n",
    " \n",
    "    len_str, len_int, len_dou = len(string_obj), len(int_obj), len(double_obj)\n",
    "    \n",
    "    # compute the values that need to be returned\n",
    "    missing_rate = number_nan/len(data)\n",
    "    \n",
    "    # Avoid 'nan' biases the value of distinct number.\n",
    "    # distinct_num = len(set(data))\n",
    "    distinct_num = len(set([item for item in data if item == item])) \n",
    "    \n",
    "    samples = data[:5]\n",
    "    \n",
    "    # add skew\n",
    "    skew = 1E7\n",
    "    kurt = 1E7\n",
    "    return_set = [missing_rate, distinct_num, skew, kurt, samples]\n",
    "\n",
    "    # RULE 1\n",
    "    if len_str > 0 and str_have_int(string_obj[0]):\n",
    "        return ['String'] + return_set\n",
    "    \n",
    "    if len(set(string_obj))>1 or len_dou + len_int == 0:\n",
    "        return ['String'] + return_set\n",
    "    elif len(set(double_obj))>1 or len_int == 0:\n",
    "        return_set[2:4] = calc_stat(double_obj)\n",
    "        return ['Double'] + return_set\n",
    "    else:\n",
    "        if str_or_int(int_obj):\n",
    "            return ['String'] + return_set\n",
    "        else:\n",
    "            return_set[2:4] = calc_stat(int_obj)\n",
    "            return ['Integer'] + return_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_have_int(string):\n",
    "    \"\"\"\n",
    "    Judge if a string has integer. Example: \"s2\" \n",
    "    \"\"\"\n",
    "    for item in string:\n",
    "        if item.isdigit():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_or_int(int_obj):\n",
    "    \"\"\"\n",
    "    Judge if a data with int type starts by 0. Example: '000025'\n",
    "    \"\"\"\n",
    "    for item in int_obj:\n",
    "        item = str(item)\n",
    "        if len(item) > 1 and item[0] == '0':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_return_type = []\n",
    "missing_rate = []\n",
    "distinct_num = []\n",
    "skew = []\n",
    "kurt = []\n",
    "samples = []\n",
    "\n",
    "#  Output the result to excel.\n",
    "for name in variable_name:\n",
    "    # index_in_sample_data = sample_variable_name.index(name)\n",
    "    variable_col_data = list(sample_data[name])  \n",
    "    return_result = judge(name, variable_col_data) \n",
    "    predict_return_type.append(return_result[0])\n",
    "    missing_rate.append(return_result[1])\n",
    "    distinct_num.append(return_result[2])\n",
    "    skew.append(return_result[3])\n",
    "    kurt.append(return_result[4])\n",
    "    samples.append(return_result[5])\n",
    "variable_data['Predict_return_type'] = predict_return_type\n",
    "variable_data['missing_rate'] = missing_rate\n",
    "variable_data['distinct_num'] = distinct_num\n",
    "variable_data['skew'] = skew\n",
    "variable_data['kurt'] = kurt\n",
    "variable_data['samples'] = samples\n",
    "variable_data.to_excel('C:/Users/zhewei/Desktop/predict10000_pri.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"----------------------PART TWO: Get Value Type-----------------------\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Split word using script provided by Wenkai.\n",
    "\"\"\"\n",
    "\n",
    "# write variable names into variable_name.txt as input file of split.py.\n",
    "f = open('C:/Users/zhewei/Desktop/material file/variable_name.txt', 'w')\n",
    "for name in variable_name:\n",
    "    f.write(name +'\\n')\n",
    "f.close()\n",
    "\n",
    "# run split.py and output new_name_tokens_v2.txt\n",
    "%run split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the file generated after spilting words and statistical word frenquency.\n",
    "\"\"\"\n",
    "var_dic = {}  # A dict storing splited word list for each variable. \n",
    "word_dic = {}  # key is word and value is its frenqucy. Example: {\"ip\": 200, \"sum\": 150...}\n",
    "f = open('C:/Users/zhewei/Desktop/material file/name_tokens_v2.txt', 'r')\n",
    "line = f.readline()\n",
    "while line:\n",
    "    line = line[:-1].split('\\t')\n",
    "    var_name = line[0]\n",
    "    word_list = line[1:]\n",
    "    for item in word_list:\n",
    "        if len(item) == 1 or item.isdigit():\n",
    "            continue\n",
    "        item = item.lower()\n",
    "        if item in word_dic:\n",
    "            word_dic[item] += 1\n",
    "        else:\n",
    "            word_dic[item] = 1\n",
    "    var_dic[var_name] = word_list\n",
    "    line = f.readline()\n",
    "f.close()\n",
    "\n",
    "# Sort word_dic by frenqucy.\n",
    "sort_word_dic = sorted(word_dic.items(), key=lambda item:item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the dimension of baseline vector.\n",
    "vector_dim = 50\n",
    "base_list = [item[0] for item in sort_word_dic[:vector_dim]]\n",
    "\n",
    "import numpy as np\n",
    "# Store vector of variables in var_vector, its key is variable name and value is vector. \n",
    "var_vector = {}\n",
    "for item in var_dic.items():\n",
    "    temp_vec = np.array([word in item[1] for word in base_list])\n",
    "    var_vector[item[0]] = list(temp_vec.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"------------------------MACHINE LEARNING------------------------\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "classifiers = [\n",
    "#         GaussianNB(),\n",
    "#         KNeighborsClassifier(30),\n",
    "#         # the number of neighbours\n",
    "#         # SVC(kernel=\"linear\", C=0.025),\n",
    "#         SVC(gamma='auto', C=1),\n",
    "        tree.DecisionTreeClassifier(max_depth=20),\n",
    "        # RandomForestClassifier(max_depth=20, n_estimators=10, max_features=1),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml(Xtrain, ytrain, Xtest):\n",
    "    \"\"\"\n",
    "    Using different machine learning functions to train labeled dataset\n",
    "    and then employ the model on all data.\n",
    "    \n",
    "    @param Xtrain: Labeled dataset \n",
    "    @param ytrain: Manually labeled result.\n",
    "    @param Xtest: All data\n",
    "    \n",
    "    @return result: A dict, its key is model name and value is corresponded result.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    f = open('C:/Users/zhewei/Desktop/ML_result.txt', 'w')\n",
    "    for model in classifiers:\n",
    "        time_start = time.time()\n",
    "        clf = model.fit(Xtrain, ytrain)\n",
    "        tree.export_graphviz(clf, out_file='C:/Users/zhewei/Desktop/tree.dot')  \n",
    "        f.write('MODEL: ')\n",
    "        f.write(str(model))\n",
    "        f.write('\\n')\n",
    "        # make predictions\n",
    "        expected = ytrain\n",
    "        predicted = model.predict(Xtrain)\n",
    "        result[str(model)] = model.predict(Xtest) \n",
    "        # summarize the fit of the model\n",
    "        f.write('RESULT\\n')\n",
    "        f.write(metrics.classification_report(expected, predicted))\n",
    "        f.write('Accuracy: ' + str(accuracy_score(expected, predicted)) + '\\n')\n",
    "        print(accuracy_score(expected, predicted))\n",
    "        f.write('CONFUSION MATRIX\\n')\n",
    "        f.write(str(metrics.confusion_matrix(expected, predicted)) + '\\n\\n')\n",
    "        print(str(time.time() - time_start) + ' seconds\\n')\n",
    "    f.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_cor(Xtrain, ytrain, Xtest, ytest, X_end):\n",
    "    \"\"\"\n",
    "    Divide labeled dataset into training dataset and test dataset. \n",
    "    Using different machine learning functions to train training dataset, \n",
    "    and test the model on test data, eventually employ models on all dataset.   \n",
    "    \n",
    "    @param Xtrain: Trainging dataset \n",
    "    @param ytrain: Manually labeled result of training dataset.\n",
    "    @param Xtest: Test dataset\n",
    "    @param ytest: Manually labeled result of test dataset.\n",
    "    \n",
    "    @return result: A dict, its key is model name and value is corresponded result.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    f = open('C:/Users/zhewei/Desktop/ML_result_cor.txt', 'w')\n",
    "    for model in classifiers:\n",
    "        time_start = time.time()\n",
    "        clf = model.fit(Xtrain, ytrain)\n",
    "        tree.export_graphviz(clf, out_file='C:/Users/zhewei/Desktop/tree_cor.dot')\n",
    "        f.write('MODEL: ')\n",
    "        f.write(str(model))\n",
    "        f.write('\\n')\n",
    "        # make predictions\n",
    "        expected = ytest\n",
    "        predicted = model.predict(Xtest)\n",
    "        result[str(model)] = model.predict(X_end) \n",
    "        # summarize the fit of the model\n",
    "        f.write('RESULT\\n')\n",
    "        f.write(metrics.classification_report(expected, predicted))\n",
    "        f.write('Accuracy: ' + str(accuracy_score(expected, predicted)) + '\\n')\n",
    "        print(accuracy_score(expected, predicted))\n",
    "        f.write('CONFUSION MATRIX\\n')\n",
    "        f.write(str(metrics.confusion_matrix(expected, predicted)) + '\\n\\n')\n",
    "        print(str(time.time() - time_start) + ' seconds\\n')\n",
    "    f.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"-----------------------------------divide the dateset for value type-------------------------------------\"\"\"\n",
    "import copy\n",
    "import pandas as pd\n",
    "# Update the variable_data using the operated file. \n",
    "variable_data2 = pd.read_excel('C:/Users/zhewei/Desktop/predict10000_pri.xlsx')\n",
    "\n",
    "# Object to be predicted\n",
    "value_type = list(variable_data2['Value Type'])\n",
    "\n",
    "# Employed Features\n",
    "var_name = list(variable_data2['Variable Name'])\n",
    "return_type = list(variable_data2['Predict_return_type'])\n",
    "var_type = list(variable_data2['Variable Type'])\n",
    "distinct_num = list(variable_data2['distinct_num'])\n",
    "missing_rate = list(variable_data2['missing_rate'])\n",
    "skew = list(variable_data2['skew'])\n",
    "kurt = list(variable_data2['kurt'])\n",
    "\n",
    "# Quantify these two features\n",
    "var_type_dic = {}\n",
    "return_type_dic = {}\n",
    "set_var_type = list(set(var_type))\n",
    "for i in range(len(set_var_type)):\n",
    "    var_type_dic[set_var_type[i]] = i\n",
    "\n",
    "set_return_type = list(set(return_type))\n",
    "for i in range(len(set_return_type)):\n",
    "    return_type_dic[set_return_type[i]] = i\n",
    "    \n",
    "# Perpare data for function ml()\n",
    "X_train_data = []\n",
    "y_train_data = []\n",
    "X_end = []\n",
    "for i in range(len(value_type)):\n",
    "    temp_feature = copy.copy(var_vector[var_name[i]])\n",
    "    temp_feature += [var_type_dic[var_type[i]], return_type_dic[return_type[i]], distinct_num[i], missing_rate[i], skew[i], kurt[i]]\n",
    "    if value_type[i] in ('CATEGORICAL', 'CONTINUOUS'):\n",
    "        X_train_data.append(temp_feature)\n",
    "        y_train_data.append(value_type[i])\n",
    "    X_end.append(temp_feature)\n",
    "assert len(X_train_data) == len(y_train_data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_data_1, X_test_data_1, y_train_data_1, y_test_data_1 = train_test_split(X_train_data, y_train_data, random_state = 4)\n",
    "# Prepare data for function ml_cor()\n",
    "# part_point = int(len(X_train_data)*0.8)\n",
    "# part_point = 7397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"-----------------------------------Label Tags-------------------------------------------\"\"\"\n",
    "import datetime\n",
    "import pandas as pd\n",
    "sample_data = pd.read_csv('C:/Users/zhewei/Desktop/material file/BREAllInOneTrack_10000.csv', sep = '\\x07', low_memory=False, encoding='utf-8')\n",
    "variable_data2 = pd.read_excel('C:/Users/zhewei/Desktop/predict10000_pri.xlsx')\n",
    "variable_name = list(variable_data2['Variable Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(variable_data2[\"Tags\"])\n",
    "for i in range(len(variable_name)):\n",
    "    variable_col_data = [str(item) for item in list(sample_data[variable_name[i]]) \n",
    "                         if (isinstance(item, float) or isinstance(item, int)) and item == item] \n",
    "    time_data_num = 0\n",
    "    no_time_data = []\n",
    "    for item in variable_col_data:\n",
    "        if '.' in item:\n",
    "            temp_item = item[:item.index('.')]\n",
    "        if len(temp_item) > 10: \n",
    "            if len(temp_item) != 13:\n",
    "                no_time_data.append(item)\n",
    "                continue\n",
    "            else:\n",
    "                item = temp_item[:10]\n",
    "        try:\n",
    "            item = float(item)\n",
    "            readable = datetime.datetime.fromtimestamp(item).isoformat()\n",
    "            if 1990 <= int(readable[:4]) <= 2050:\n",
    "                time_data_num += 1\n",
    "            else:\n",
    "                no_time_data.append(item)\n",
    "        except:\n",
    "            no_time_data.append(item)\n",
    "    if time_data_num > 0 and len(set(no_time_data)) <= 1:\n",
    "        tags[i] = \"SUP: TIMESTAMP\"\n",
    "variable_data2['Predicted Tags'] = tags\n",
    "variable_data2.to_excel('C:/Users/zhewei/Desktop/predict10000_tag2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(variable_data2[\"Tags\"])\n",
    "used_models = list(variable_data2[\"Used Models\"])\n",
    "assigned_tags_id = [i for i in range(len(tags)) if (tags[i] == tags[i] or used_models[i] == used_models[i]) \n",
    "                    and \"MODELSCORE\" not in str(tags[i]) and \"TIMESTAMP\" not in str(tags[i])]\n",
    "\n",
    "assigned_tags_re = []\n",
    "temp = []\n",
    "for id_ in assigned_tags_id:\n",
    "    if tags[id_] != tags[id_]:\n",
    "        assigned_tags_re.append(\"-SUP\")\n",
    "    elif \"SUP: NS\" in tags[id_]:\n",
    "        assigned_tags_re.append(tags[id_][tags[id_].index(\"SUP: \"):])\n",
    "#     elif \"SUP: MODELSCORE\" in tags[id_] or  \"SUP: TIMESTAMP\" in tags[id_]: \n",
    "#         assigned_tags_id.remove(id_)\n",
    "    elif \"SUP:\" in tags[id_]:\n",
    "        temp.append(id_)\n",
    "        assigned_tags_re.append(\"SUP: RAWKEY\")\n",
    "    else:\n",
    "        assigned_tags_re.append(\"-SUP\")\n",
    "splited_words = []\n",
    "for i in range(len(temp)):\n",
    "    splited_words += [word.lower() for word in var_dic[var_name[temp[i]]] if len(word) > 1 and (not word.isdigit())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dic_ = dict()\n",
    "for item in splited_words:\n",
    "    if item not in dic_:\n",
    "        dic_[item] = 1\n",
    "    else:\n",
    "        dic_[item] += 1\n",
    "        \n",
    "vector_dim = 20\n",
    "base_vec = [item[0] for item in sorted(dic_.items(), key=lambda x: x[1], reverse=True)[:20]]\n",
    "\n",
    "# Store vector of variables in var_vector, its key is variable name and value is vector. \n",
    "var_vector = {}\n",
    "for item in var_dic.items():\n",
    "    temp_vec = np.array([word in item[1] for word in base_vec])\n",
    "    var_vector[item[0]] = list(temp_vec.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"-----------------------------------divide the dateset for model usage-------------------------------------\"\"\"\n",
    "import copy\n",
    "import pandas as pd\n",
    "# Update the variable_data using the operated file. \n",
    "variable_data2 = pd.read_excel('C:/Users/zhewei/Desktop/predict_all.xlsx')\n",
    "\n",
    "# Object to be predicted\n",
    "tags = list(variable_data2[\"Tags\"])\n",
    "used_models = list(variable_data2[\"Used Models\"])\n",
    "assigned_tags_id = [i for i in range(len(tags)) if (tags[i] == tags[i] and \"MODELSCORE\" not in tags[i] \n",
    "                    and \"TIMESTAMP\" not in tags[i]) or used_models[i] == used_models[i]]\n",
    "0\n",
    "assigned_tags_re = []\n",
    "for id_ in assigned_tags_id:\n",
    "    if tags[id_] != tags[id_]:\n",
    "        assigned_tags_re.append(\"-SUP\")\n",
    "    elif \"SUP: NS\" in tags[id_]:\n",
    "        assigned_tags_re.append(tags[id_][tags[id_].index(\"SUP: \"):])\n",
    "#     elif \"SUP: MODELSCORE\" in tags[id_] or  \"SUP: TIMESTAMP\" in tags[id_]: \n",
    "#         assigned_tags_id.remove(id_)\n",
    "    elif \"SUP:\" in tags[id_]:\n",
    "        assigned_tags_re.append(\"SUP: RAWKEY\")\n",
    "    else:\n",
    "        assigned_tags_re.append(\"-SUP\")\n",
    "        \n",
    "assert len(assigned_tags_id) == len(assigned_tags_re)\n",
    "        \n",
    "# Employed Features\n",
    "var_name = list(variable_data2['Variable Name'])\n",
    "return_type = list(variable_data2['Predict_return_type'])\n",
    "var_type = list(variable_data2['Variable Type'])\n",
    "distinct_num = list(variable_data2['distinct_num'])\n",
    "missing_rate = list(variable_data2['missing_rate'])\n",
    "skew = list(variable_data2['skew'])\n",
    "kurt = list(variable_data2['kurt'])\n",
    "\n",
    "# Quantify these two features\n",
    "var_type_dic = {}\n",
    "return_type_dic = {}\n",
    "set_var_type = list(set(var_type))\n",
    "for i in range(len(set_var_type)):\n",
    "    var_type_dic[set_var_type[i]] = i\n",
    "\n",
    "set_return_type = list(set(return_type))\n",
    "for i in range(len(set_return_type)):\n",
    "    return_type_dic[set_return_type[i]] = i\n",
    "    \n",
    "# Perpare data for function ml()\n",
    "X_train_data = []\n",
    "y_train_data = []\n",
    "X_end = []\n",
    "for i in range(len(tags)):\n",
    "    temp_feature = copy.copy(var_vector[var_name[i]])\n",
    "    temp_feature += [var_type_dic[var_type[i]], return_type_dic[return_type[i]], distinct_num[i], missing_rate[i], skew[i], kurt[i]]\n",
    "    if i in assigned_tags_id:\n",
    "        X_train_data.append(temp_feature)\n",
    "        y_train_data.append(assigned_tags_re[assigned_tags_id.index(i)])\n",
    "    X_end.append(temp_feature)\n",
    "assert len(X_train_data) == len(y_train_data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_data_1, X_test_data_1, y_train_data_1, y_test_data_1 = train_test_split(X_train_data, y_train_data, random_state = 4)\n",
    "# Prepare data for function ml_cor()\n",
    "# part_point = int(len(X_train_data)*0.8)\n",
    "# part_point = 7397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.10199642181396484 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning process\n",
    "import time\n",
    "result_dic = ml(X_train_data, y_train_data, X_end)\n",
    "result_dic = ml_cor(X_train_data_1, y_train_data_1, X_test_data_1, y_test_data_1, X_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the result from Decision Tree into output file.\n",
    "predict_value_type = []\n",
    "for (key, value) in result_dic.items():\n",
    "    if 'DecisionTreeClassifier' in key:\n",
    "        predict_value_type = value\n",
    "        break\n",
    "        \n",
    "# Write the result from Decision Tree into output file.\n",
    "output_data = pd.read_excel('C:/Users/zhewei/Desktop/predict_all.xlsx')\n",
    "predict_value_type = []\n",
    "for (key, value) in result_dic.items():\n",
    "    if 'DecisionTreeClassifier' in key:\n",
    "        predict_value_type = value\n",
    "        break\n",
    "output_data['predicted_tags'] = predict_value_type\n",
    "output_data.to_excel('C:/Users/zhewei/Desktop/end_predict10000v2.1.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
